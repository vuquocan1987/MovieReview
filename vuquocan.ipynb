{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Untitled0.ipynb","provenance":[{"file_id":"1ITMW6ZRdURBM9nAv-HQseK5eWVJrf1rv","timestamp":1586530348245}],"toc_visible":true,"authorship_tag":"ABX9TyNZf9IEGlGNXMtTUk+qfI7Z"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fCTfJTmVLIAc","colab_type":"text"},"source":["# MOVIE REVIEW CLASSIFICATION\n","\n","Well, let cut it to the chase, this is a project to show case my understanding of IF-TDF and some basic idea of how processing text working in real world. With all the state-of-the-art machine learning model out-there I don't think mine would make any tiny change to the world. However admittedly, it's very valuable for me as someone who is trying to get my feet wet with machine learning world, and I would definitely recommend anyone who is learning attempt this tiny project ( To be honest, It would be more of a tutorial to me, I literally just get the code from our tutorial ...)\n","\n","## Introduction\n","The World Wide Web contains an enourmous amount of documents that is easily accessiable. Obtaining the valuable insight from this corpus of information is considered to be next step of our industry evolution. We collect large amount feed back from customer and a tools to classify these feed back is in needs. Movie likewise is the most important information for user who go to movie. This small collab sessions will introduce some basic techniques that is used in text classification: Preprocessing, TF-IDF, Logistic Regression.\n"]},{"cell_type":"markdown","metadata":{"id":"JM-5HRHaSSbz","colab_type":"text"},"source":["#Loading Data\n","\n","The files contains list of reviews and its sentiments. First we need to load it to a pandas data frame, and check for data type and columns."]},{"cell_type":"code","metadata":{"id":"rega-Kr9k7Zs","colab_type":"code","outputId":"b45c2317-2910-497a-974e-9bfc570b3283","executionInfo":{"status":"ok","timestamp":1586661017891,"user_tz":-420,"elapsed":850,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iG5x_hRDlbbQ","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","review = pd.read_csv('/content/drive/My Drive/Student Files/FTMLE - Tonga/Data/movie_review.csv', encoding='utf-8', sep='\\t')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e3y4vrLfpcCi","colab_type":"code","outputId":"fae42d6b-12c6-4379-f047-56a198bfb7cf","executionInfo":{"status":"ok","timestamp":1586661018217,"user_tz":-420,"elapsed":1162,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["review.head()"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5814_8</td>\n","      <td>With all this stuff going down at the moment w...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2381_9</td>\n","      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>7759_3</td>\n","      <td>The film starts with a manager (Nicholas Bell)...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3630_4</td>\n","      <td>It must be assumed that those who praised this...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9495_8</td>\n","      <td>Superbly trashy and wondrously unpretentious 8...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       id                                             review  sentiment\n","0  5814_8  With all this stuff going down at the moment w...          1\n","1  2381_9  \\The Classic War of the Worlds\\\" by Timothy Hi...          1\n","2  7759_3  The film starts with a manager (Nicholas Bell)...          0\n","3  3630_4  It must be assumed that those who praised this...          0\n","4  9495_8  Superbly trashy and wondrously unpretentious 8...          1"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"JowEjrSMpdG4","colab_type":"code","outputId":"af6b1c8a-f47b-4f3d-a95f-f031177a78f7","executionInfo":{"status":"ok","timestamp":1586661018217,"user_tz":-420,"elapsed":1156,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["review.tail()"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>22495</th>\n","      <td>3453_3</td>\n","      <td>It seems like more consideration has gone into...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22496</th>\n","      <td>5064_1</td>\n","      <td>I don't believe they made this film. Completel...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22497</th>\n","      <td>10905_3</td>\n","      <td>Guy is a loser. Can't get girls, needs to buil...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22498</th>\n","      <td>10194_3</td>\n","      <td>This 30 minute documentary BuÃ±uel made in the...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22499</th>\n","      <td>8478_8</td>\n","      <td>I saw this movie as a child and it broke my he...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            id                                             review  sentiment\n","22495   3453_3  It seems like more consideration has gone into...          0\n","22496   5064_1  I don't believe they made this film. Completel...          0\n","22497  10905_3  Guy is a loser. Can't get girls, needs to buil...          0\n","22498  10194_3  This 30 minute documentary BuÃ±uel made in the...          0\n","22499   8478_8  I saw this movie as a child and it broke my he...          1"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"QdBbXSvQSXyY","colab_type":"text"},"source":["##Preprocessing\n","Raw data can be hard for machine learning algorithem process, sometime, impossible. To improve training time and accuracy we can apply some processing ( called preprocessing ) on our data.\n","\n","## Stemming\n","The words can have numerous forms, even thought they have roughly same nuance in the text, but the machine learning model treat them differently, to optimize training speed of the model, it's may be of benefit to reduce all the word to its stem."]},{"cell_type":"code","metadata":{"id":"3RGXYn7bvnHE","colab_type":"code","outputId":"52d2fb0e-5b86-4fb9-8df4-8088ce6bbcc1","executionInfo":{"status":"ok","timestamp":1586661018587,"user_tz":-420,"elapsed":1520,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["import nltk\n","nltk.download('stopwords')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"cmiNIjBZvN6c","colab_type":"code","colab":{}},"source":["from nltk.corpus import stopwords\n","stop = stopwords.words('english')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSDRJvAetHVL","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.stem import PorterStemmer\n","porter = PorterStemmer()\n","import re\n","def tokenizer_porter(text):\n","    # Stemming\n","    return [porter.stem(word) for word in text.split()]\n","\n","def preprocessor(text):\n","    \"\"\" Return a cleaned version of text\n","    \"\"\"\n","    # Remove HTML markup\n","    text = re.sub('<[^>]*>', '', text)\n","    # Save emoticons for later appending\n","    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n","    # Remove any non-word character and append the emoticons,\n","    # removing the nose character for standarization. Convert to lower case\n","    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' + ' '.join(emoticons).replace('-', ''))\n","    \n","    return text\n","# Create a tfidf vectorizer\n","tfidf = TfidfVectorizer(stop_words=stop, tokenizer = tokenizer_porter,preprocessor = preprocessor)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QrJmBHw4vOmp","colab_type":"text"},"source":["#Start Traing\n","One of the most simple machine learning model to classify is logistic regression, and we are going to use that model in this collab."]},{"cell_type":"code","metadata":{"id":"xFxKo9psvs1z","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X = review.review\n","y = review.sentiment\n","X_train,x_test,y_train,y_test = train_test_split(X, y, test_size = .2)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jVN3oxXbvqUq","colab_type":"text"},"source":["We create a Pipeline and start feeding the data in to the pipeline."]},{"cell_type":"code","metadata":{"id":"IOg894E2wnis","colab_type":"code","outputId":"f5f4b55a-6996-4710-d1aa-faf104ffcb8d","executionInfo":{"status":"ok","timestamp":1586661085447,"user_tz":-420,"elapsed":68326,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":462}},"source":["from sklearn.pipeline import Pipeline\n","from sklearn.linear_model import LogisticRegression\n","clf = Pipeline([('vect',tfidf),('clf',LogisticRegression(random_state=0))])\n","clf.fit(X_train,y_train)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'ani', 'becaus', 'befor', 'doe', 'dure', 'ha', 'hi', 'onc', 'onli', 'ourselv', 'themselv', 'thi', 'veri', 'wa', 'whi', 'yourselv'] not in stop_words.\n","  'stop_words.' % sorted(inconsistent))\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["Pipeline(memory=None,\n","         steps=[('vect',\n","                 TfidfVectorizer(analyzer='word', binary=False,\n","                                 decode_error='strict',\n","                                 dtype=<class 'numpy.float64'>,\n","                                 encoding='utf-8', input='content',\n","                                 lowercase=True, max_df=1.0, max_features=None,\n","                                 min_df=1, ngram_range=(1, 1), norm='l2',\n","                                 preprocessor=<function preprocessor at 0x7f4714be2ea0>,\n","                                 smooth_idf=True,\n","                                 stop_words=['i', 'me', 'my', 'myself', '...\n","                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n","                                 tokenizer=<function tokenizer_porter at 0x7f4714be2f28>,\n","                                 use_idf=True, vocabulary=None)),\n","                ('clf',\n","                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n","                                    fit_intercept=True, intercept_scaling=1,\n","                                    l1_ratio=None, max_iter=100,\n","                                    multi_class='auto', n_jobs=None,\n","                                    penalty='l2', random_state=0,\n","                                    solver='lbfgs', tol=0.0001, verbose=0,\n","                                    warm_start=False))],\n","         verbose=False)"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"lChQpxhBv1CN","colab_type":"text"},"source":["Checking the model accuracy."]},{"cell_type":"code","metadata":{"id":"1-0iRczrxPQ9","colab_type":"code","outputId":"67f35562-6653-4e16-ef57-f4f1438d823e","executionInfo":{"status":"ok","timestamp":1586661102148,"user_tz":-420,"elapsed":85007,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","predictions = clf.predict(x_test)\n","accuracy_score(y_test,predictions)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8855555555555555"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"Za-g9IVxVOt0","colab_type":"text"},"source":["# Retest on validation data\n"]},{"cell_type":"code","metadata":{"id":"i_gdQbOiVMpS","colab_type":"code","colab":{}},"source":["retest = pd.read_csv('/content/drive/My Drive/Student Files/FTMLE - Tonga/Data/movie_review_evaluation.csv', encoding='utf-8', sep='\\t')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FDfQZpjX4CH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"outputId":"da9fc10f-3502-470b-bf98-b246211a49ed","executionInfo":{"status":"ok","timestamp":1586661156098,"user_tz":-420,"elapsed":684,"user":{"displayName":"Quoc An Vu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXE5n8KXrM880oVNKx4g8V69O-1Q0lX5SHq1tI=s64","userId":"08190190040011513902"}}},"source":["retest.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>review</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10633_1</td>\n","      <td>I watched this video at a friend's house. I'm ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4489_1</td>\n","      <td>`The Matrix' was an exciting summer blockbuste...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3304_10</td>\n","      <td>This movie is one among the very few Indian mo...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3350_3</td>\n","      <td>The script for this movie was probably found i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1119_1</td>\n","      <td>Even if this film was allegedly a joke in resp...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id                                             review\n","0  10633_1  I watched this video at a friend's house. I'm ...\n","1   4489_1  `The Matrix' was an exciting summer blockbuste...\n","2  3304_10  This movie is one among the very few Indian mo...\n","3   3350_3  The script for this movie was probably found i...\n","4   1119_1  Even if this film was allegedly a joke in resp..."]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"Sbv6DbTaX_08","colab_type":"code","colab":{}},"source":["X_validation = retest['review']\n","\n","y_validation = clf.predict(X_validation)\n","retest['prediction'] = y_validation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8mjB2IqZanjp","colab_type":"code","colab":{}},"source":["retest.to_csv('drive/My Drive/vuquocan.csv')"],"execution_count":0,"outputs":[]}]}